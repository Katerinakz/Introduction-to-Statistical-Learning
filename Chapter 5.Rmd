---
title: "Chapter 5 ISLR"
author: "KK"
date: "3/25/2021"
output: html_document
---

```{r setup, include=FALSE}

```

## R Markdown


```{}
glm.fit <- glm(mpg~horsepower, data=Auto)
coef(glm.fit)

lm.fit=lm(mpg~horsepower, data=Auto)
coef(lm.fit)

library(boot)
glm.fit=glm(mpg~horsepower, data=Auto)
cv.err=cv.glm(Auto,glm.fit)
cv.err$delta
help(cv.glm)

cv.error=rep(0,5)
for (i in 1:5){
  glm.fit=glm(mpg~poly(horsepower, i), data=Auto)
  cv.error[i]=cv.glm(Auto, glm.fit)$delta[1]
}
cv.error

#k-fold cross validation
set.seed(17)
cv.error.10=rep(0,10)
for(i in 1:10){
  glm.fit=glm(mpg~poly(horsepower,i), data=Auto)
  cv.error.10[i]=cv.glm(Auto, glm.fit, K=10)$delta[1]
}
cv.error.10


#Bootstrap
alpha.fn <- function(data, index){
  X<- data$X[index]
  Y<- data$Y[index]
  return ((var(Y)-cov(X,Y))/ var(X)+var(Y)-2*cov(X,Y))
}

alpha.fn(Portfolio, 1:100)

set.seed(1)
alpha.fn(Portfolio, sample(100, 100, replace=T))


boot(Portfolio, alpha.fn, R=10000)

set.seed(1)
boot.fn <- function(data, index){
  return(coef(lm(mpg~horsepower, data=data, subset=index)))
}

boot.fn(Auto, sample(392, 392, replace=TRUE))
boot.fn(Auto, sample(392, 392, replace=TRUE))


boot(Auto, boot.fn, R=1000)


store=rep (NA , 10000)
for (i in 1:10000) {
  store[i]=sum(sample (1:100 , rep =TRUE)==4) >0
}
mean(store)

sample (1:100 , rep =TRUE)==4


#Exercises Applied
#5
set.seed(1)
Default$default <- as.factor(Default$default)
glm.model <- glm(default ~income+ balance, data=Default, family="binomial")
summary(glm.model)


library(caTools)
split <- sample.split(Default$default, SplitRatio=0.8)
train <- subset(Default, split==TRUE)
test <- subset(Default, split==FALSE)

glm.train <- glm(default~income+balance, data=train, family="binomial")
test$predictions <- predict(glm.train, test, type="response")
preds <- function(a){
  if (a>0.5){
    return(1)
  }else{
    return(0)
  }
}
test$predictions1<- sapply(test$predictions, preds)

def <- function(a){
  if (a=="No"){
    return(0)
  }else{
    return(1)
  }
}
test$def <- sapply(test$default, def)
mean(test$predictions1 != test$def)



library(fastDummies)
Default <- dummy_cols(Default, select_columns = "student", 
                        remove_first_dummy = TRUE)

glm.model2 <- glm(default~income+balance+student_Yes,data=Default,
                  family="binomial")
cv.err <- cv.glm(Default, glm.model2, K=10)
cv.err$delta
#Adding a dummy variable leads to a small reduction in the test error rate

#Exercise #6
model <-glm(default~income+balance, data=Default, family="binomial")
summary(model)

boot.fn<-function(Default, index){
  return(coef(lm(default~income+balance, data=Default, subset=index)))
}
boot(Default, boot.fn, R=10000  )

-0.270     
#Exercise 7
glm.model <- glm(Direction~Lag1+Lag2, data=Weekly, family="binomial")
glm.model2 <-glm(Direction~Lag1+Lag2, data=tail(Weekly, -1), family=
                   "binomial")
predictions <- predict(glm.model2,head(Weekly,1), type="response")
predictions
head(Weekly,1)

loocv.err=rep(0,1089)
set.seed(1)
for (i in 1:1089 ){
  glm.fit=glm(Direction~Lag1+Lag2, data=Weekly[-i,], family="binomial")
  mypred<- ifelse(predict(glm.fit, Weekly[i,], type="response")>0.5,
                  "Up", "Down")
  loocv.err[i]<- ifelse(Weekly[i,]$Direction==mypred, 0, 1)
}
str(loocv.err)
mean(loocv.err)
#44.99 % of st error based on Loocv method.

# Exercise 8
#8a
set.seed(1)
x=rnorm(100)
y=x-2*x^2+rnorm(100)
#n is 100 observations
#p is 2 variables
#y=x-2x^2 + epsilon

#8b
library(ggplot2)
plot(x,y)
#the relationship between x and y is quadratic


data <-data.frame(y,x, x2=x^2, x3=x^3, x4=x^4)


#8c
set.seed(3)
model <-glm(y~x, data=data)
cv.error <-cv.glm(data,model)$delta[1]
model2 <-glm(y~x+x2, data=data)
cv.error2 <-cv.glm(data,model2)$delta[1]
model3 <-glm(y~x+x2+x3, data=data)
cv.error3 <-cv.glm(data,model3)$delta[1]
model4 <-glm(y~x+x2+x3+x4, data=data)
cv.error4 <-cv.glm(data,model4)$delta[1]

cv.error
cv.error2
cv.error3
cv.error4

#Results are the same if you change the seed, because there is no
#randomness in LOOCV. 
#The quadratic model had the lowest error. I expected this because 
#the relationship between y and x is quadratic, as we saw on the scatter plot 
#we did on the previous question.

#Exercise 9
#a
library(MASS)
library(ISLR)
library(boot)
meanu <- mean(Boston$medv)
meanu

#b
stdu <-sd(Boston$medv)/sqrt(nrow(Boston))
stdu

#c
mean.fn <- function(data, m){
  return(mean(data[m]))
}
stdboot<- boot(Boston$medv,mean.fn, R=100)

#d
t.test(Boston$medv)
#0.3980796
conf.int.95.1<- mean(Boston$medv)-2*0.3980796
conf.int.95.2 <- mean(Boston$medv)+2*0.3980796
conf.int.95.1
conf.int.95.2 

#e
median.u <- median(Boston$medv)
median.u

#f
median.fn <-function(data, m){
  return(median(data[m]))
}
boot(Boston$medv, median.fn, R=100)

#g
quant.10 <- quantile(Boston$medv,0.1)
quant.10

#h
quan.10fn <- function(data,m){
  return(quantile(data[m],0.1))
}
boot(Boston$medv, quan.10fn, R=100)
#Estimated std is 0.489

```



```{r pressure, echo=FALSE}
plot(pressure)
```

